{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c6730f-5d76-450b-9788-ec883d024f57",
   "metadata": {},
   "source": [
    "# Hugging Face Transformers 微调训练入门\n",
    "\n",
    "本示例将介绍基于 Transformers 实现模型微调训练的主要流程，包括：\n",
    "- 数据集下载\n",
    "- 数据预处理\n",
    "- 训练超参数配置\n",
    "- 训练评估指标设置\n",
    "- 训练器基本介绍\n",
    "- 实战训练\n",
    "- 模型保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0b1e12-1921-4438-8d5d-9760a629dcfe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## YelpReviewFull 数据集\n",
    "\n",
    "**Hugging Face 数据集：[ YelpReviewFull ](https://huggingface.co/datasets/yelp_review_full)**\n",
    "\n",
    "### 数据集摘要\n",
    "\n",
    "Yelp评论数据集包括来自Yelp的评论。它是从Yelp Dataset Challenge 2015数据中提取的。\n",
    "\n",
    "### 支持的任务和排行榜\n",
    "文本分类、情感分类：该数据集主要用于文本分类：给定文本，预测情感。\n",
    "\n",
    "### 语言\n",
    "这些评论主要以英语编写。\n",
    "\n",
    "### 数据集结构\n",
    "\n",
    "#### 数据实例\n",
    "一个典型的数据点包括文本和相应的标签。\n",
    "\n",
    "来自YelpReviewFull测试集的示例如下：\n",
    "\n",
    "```json\n",
    "{\n",
    "    'label': 0,\n",
    "    'text': 'I got \\'new\\' tires from them and within two weeks got a flat. I took my car to a local mechanic to see if i could get the hole patched, but they said the reason I had a flat was because the previous patch had blown - WAIT, WHAT? I just got the tire and never needed to have it patched? This was supposed to be a new tire. \\\\nI took the tire over to Flynn\\'s and they told me that someone punctured my tire, then tried to patch it. So there are resentful tire slashers? I find that very unlikely. After arguing with the guy and telling him that his logic was far fetched he said he\\'d give me a new tire \\\\\"this time\\\\\". \\\\nI will never go back to Flynn\\'s b/c of the way this guy treated me and the simple fact that they gave me a used tire!'\n",
    "}\n",
    "```\n",
    "\n",
    "#### 数据字段\n",
    "\n",
    "- 'text': 评论文本使用双引号（\"）转义，任何内部双引号都通过2个双引号（\"\"）转义。换行符使用反斜杠后跟一个 \"n\" 字符转义，即 \"\\n\"。\n",
    "- 'label': 对应于评论的分数（介于1和5之间）。\n",
    "\n",
    "#### 数据拆分\n",
    "\n",
    "Yelp评论完整星级数据集是通过随机选取每个1到5星评论的130,000个训练样本和10,000个测试样本构建的。总共有650,000个训练样本和50,000个测试样本。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fedd08-e5fd-4dc1-9e57-02045e986d1a",
   "metadata": {},
   "source": [
    "## 全局变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "271774bf-ca54-4105-a581-0ef9f6446a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手动下载模型，使用huggingface-cli\n",
    "# huggingface-cli download --resume-download bert-base-cased --local-dir bert-base-cased\n",
    "dataset_name_or_path = \"/root/autodl-tmp/hf/hub/datasets--yelp_review_full/yelp_review_full\"\n",
    "model_name_or_path = \"/root/autodl-tmp/hf/hub/bert-base-cased\"\n",
    "metric_name_or_path = \"/root/evaluate/metrics/accuracy/accuracy.py\"\n",
    "\n",
    "model_output_dir = \"/root/autodl-tmp/models/bert-base-cased-finetune-yelp\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09446b3-c1f5-4fed-9667-5834eede80d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 环境设置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27b59d4-f7ef-4fe4-a77d-e71ab1ad8076",
   "metadata": {},
   "source": [
    "### 设置代理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe938356-89c5-45f0-8044-8a08746da485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4c4b8d9-5589-48b1-ba12-0bf47ce18677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://100.72.64.19:12798 http://100.72.64.19:12798\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ['http_proxy'], os.environ['https_proxy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a761546d-cfe0-466b-8345-de6a3fe26e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 设置HF环境变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf1ff6a-8ec8-4ad5-aa3c-791011e7475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_DATASETS_OFFLINE\"] = \"1\"\n",
    "os.environ[\"HUGGINGFACE_CO_RESOLVE_ENDPOINT\"] = \"https://hf-mirror.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae019bfa-87a1-4bfa-a63d-f38d8293d1df",
   "metadata": {},
   "source": [
    "### 还原环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16cceacf-2cb3-479d-802f-3caa5e8de87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_DATASETS_OFFLINE\"] = \"\"\n",
    "os.environ[\"HUGGINGFACE_CO_RESOLVE_ENDPOINT\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5085e66b-ef67-4e9e-b15d-1cc848a5ee2b",
   "metadata": {},
   "source": [
    "### 确认环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aab90ff-03db-4fa8-ac6e-2745ecb4b697",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'HF_DATASETS_OFFLINE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# print(os.environ[\"HF_ENDPOINT\"])\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print(os.environ[\"HUGGINGFACE_CO_RESOLVE_ENDPOINT\"])\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHF_DATASETS_OFFLINE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.10/os.py:680\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    677\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodekey(key)]\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# raise KeyError with the original key value\u001b[39;00m\n\u001b[0;32m--> 680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodevalue(value)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'HF_DATASETS_OFFLINE'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ[\"HF_ENDPOINT\"])\n",
    "print(os.environ[\"HUGGINGFACE_CO_RESOLVE_ENDPOINT\"])\n",
    "print(os.environ[\"HF_DATASETS_OFFLINE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3384512-338e-40d1-a44a-b3e32fc26d73",
   "metadata": {},
   "source": [
    "## 下载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bbf72d6c-7ea5-4ee1-969a-c5060b9cb2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(dataset_name_or_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0182db-3da6-410a-945b-28adc101da21",
   "metadata": {},
   "source": [
    "## 阅览数据集\n",
    "### 数据集对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec6fc806-1395-42dd-8121-a6e98a95cf01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 650000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4653562c-0f98-4644-b937-a1fa9d105689",
   "metadata": {},
   "source": [
    "### 抽查一条数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c94ad529-1604-48bd-8c8d-aa2f3bca6200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 2,\n",
       " 'text': \"As far as Starbucks go, this is a pretty nice one.  The baristas are friendly and while I was here, a lot of regulars must have come in, because they bantered away with almost everyone.  The bathroom was clean and well maintained and the trash wasn't overflowing in the canisters around the store.  The pastries looked fresh, but I didn't partake.  The noise level was also at a nice working level - not too loud, music just barely audible.\\\\n\\\\nI do wish there was more seating.  It is nice that this location has a counter at the end of the bar for sole workers, but it doesn't replace more tables.  I'm sure this isn't as much of a problem in the summer when there's the space outside.\\\\n\\\\nThere was a treat receipt promo going on, but the barista didn't tell me about it, which I found odd.  Usually when they have promos like that going on, they ask everyone if they want their receipt to come back later in the day to claim whatever the offer is.  Today it was one of their new pastries for $1, I know in the summer they do $2 grande iced drinks with that morning's receipt.\\\\n\\\\nOverall, nice working or socializing environment.  Very friendly and inviting.  It's what I've come to expect from Starbucks, so points for consistency.\"}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][111]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50439ab8-a0b4-4fcd-98ed-aea312af967f",
   "metadata": {},
   "source": [
    "### 随机阅览一组数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dc45997-e391-456f-b0b9-d3193b0f6a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e2ecebb-d5d1-456d-967c-842a79fdd622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    # display(df)  # 会被缩略显示。换行符被保留\n",
    "    # display(df.to_html())  # html string。html标签、换行符皆被保留\n",
    "    display(HTML(df.to_html()))  # 换行符被保留"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1af560b6-7d21-499e-9b82-114be371a98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 star</td>\n",
       "      <td>I took my Subaru there for repair.  Some employees are nice and welcoming and some are mean, but that is expected of car mechanics, i guess.  Also (as expected) prices are high for parts and labor.  What I did not expect was to have the car returned to me with defective repairs and the cabin full of grease.  The dealers also recommended thousand of dollars in repairs, which according to several other mechanics are absolutely not necessary.\\n\\nTo their credit, the service was very reasonable and did fix defective repairs after these were brought up to his attention.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 star</td>\n",
       "      <td>Man, it seems I have been giving a lot of two stars lately.  I was in the mood for a burger and in the Scottsdale area with my nephew.  We decided to give Lush Burger a try.  We sat outside (first off - BAD IDEA - there are FLIES everywhere trying to take a nibble off your gobble).  \\n\\nFirst, we ordered the chicken wings - completely MEDIOCRE at best (I am a wing junkie and this is one I would never order again, respectfully).\\n\\nFrom there, ordered the burger, fries (both regular and truffle) and we each got a burger (I went with the \\\"Western\\\" which is basically like a carls Jr. \\\"western bacon cheeseburger.\\\"  Burger was pretty good (Gigantic, even a big mouth like me had trouble taking a bite if you like those kinds of burgers) but not amaze balls or anything like that.\\n\\nFinally, being a foodie connoisseur, tried their deserts.  Lush was pretty good in this area.  Had their peanut butter shake - DELISH, and their cinnamon donuts (Lushpuppies I think they call them), also very good although seemed like they were not fully deep fried in the middle, but all in all the deserts were the best part of the meal.\\n\\nAttorney Steve Tip: When I ate here, (while chewing) the thought kept occurring to me \\\"I wish I was at Bobby Q's\\\" off the 17th.  That is the best burger around, and their cinnamon donuts (FREE AT THE END OF YOUR MEAL) are better than Lush.  I know this is completely digressing and on the other side of town, but if it were me, I would take my nephew to Bobby Q's next time.  IN fact, I told my nephew that.  You might want to do yourself the favor and head their in the first place if you are looking for the KILLER BURGER.  I wrote a review on them so check that out for more specific information.  Anyway, when I start daydreaming about other restaurants, that is when I pull out the two star.  Sorry guys, your place seemed real nice and all (waitress and staff were exceptional, let me not forget to give a shout out for that) but I don't think I will be stopping in again.\\n\\nPeace out\\n\\nFind your Sizzle!\\n\\nAttorney Steve, the business and real estate lawyer\\n\\nhttp://www.vondranlaw.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5 stars</td>\n",
       "      <td>Regarding the long waits, it's because they take their time. One of the best haircuts I've had in awhile.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 star</td>\n",
       "      <td>This was a bustling little restaurant that I dropped in to get a takeout dinner. Very pleasant and friendly personnel, and my chili relleno/taco combo was good, except for the side of rice which was dry and under cooked. The salsa was thick, tasty, and medium hot, and there was an accompanying warm flour tortilla. Overall good, but not exceptional.\\nThere is no excuse for undercooked rice; this is a rookie mistake and should have been caught before leaving the kitchen. I give them a zero for quality check on this one.\\nPros: Right in the downtown area, with good atmosphere, friendly service, and plenty of on and off street parking. Alcohol served. Portion size and value OK.\\nCons:As above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 star</td>\n",
       "      <td>I've tried Flip'n Chicken 3 times at this point and if you like incorrect orders &amp; lack luster service this is the place for you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3 stars</td>\n",
       "      <td>Fried chicken wings with many flavors as options and dipping sauces, SOLD. I love me some chicken wings and wings top may have the meatiest around. I unfortunately found them to be a lot more greasy than some other places but the size and flavor options made the a decent ouch choice.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1 star</td>\n",
       "      <td>I don't know what to say here. I guess I went in on a bad night. I'm in town for work, so I went through the drive through to get a beef and cheddar and some potato cakes to munch on in my hotel room. When I got to the hotel room (the Aliante, which is minutes away) the bag was saturated with grease (see photo). I immediately went back and the crew working were unfriendly and unapologetic. No apologies or any sense of compassion. When I first walked in and told them about my greasy bag, the punk kid working the counter rolled his eyes and told some woman, you deal with this. She was equally as unpleasant as him. What a crew full of jerks!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4 stars</td>\n",
       "      <td>i only get the chicken katsu here or the chicken katsu curry.  Ohana is one of the few places that uses chicken breasts instead of thighs for their katsu which is great.  ive tried the hawaiian bbq beef which was a little chewy and the garlic shrimp was a tad oily.  i cannot complain about the chicken katsu curry. \\n\\nHowever the curry is like a thai curry.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5 stars</td>\n",
       "      <td>I've walked into a few different nail salons in the area and have been pretty disappointed every time. Today I decided to check out the ever faithful Yelp and was thrilled with the outcome. I had a mani/pedi. The salon is very professional and clean and Kim did a perfect job for me! Yay Yelp!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4 stars</td>\n",
       "      <td>So I meet up the homie Mike C. at this place. Been wanting to try it for a minute now. It's eveningish and not busy at all.  It has a nice, dark, and clean ambiance. I'm not too sure on the dynamics of this establishment. We were the ones manning the grill, which I had no problem with. I've had places where an angry looking Korean lady snatches the tongs away and takes over. It wasn't the usual AYCE but I'll still pho'ks with it. \\n\\nThe dishes we sampled was the carpaccio, pork belly, brisket, filet mignon, and prime kalbi.\\n\\nI saw on Yelp that this place had beef carpaccio. Ever since Woonam Jung stopped serving carpaccio, I've been looking for another joint to replace that empty spot in my heart. Gangnam's carpaccio wasn't as extravagant as Woonam's, but just as good. Served on an oily sauce and some greens on top. Simple and delicious. This was my favorite during the feeding.\\n\\nThe pork belly and brisket. What can you say? It's always good. There is nothing special about these other than the pork belly being thick. Dip them things in the sesame -salt &amp; pepper concoction and you got a happy customer. \\n\\nALRIGHTY THEN!  Now to the beef. The filet mignon was good and tender. We cooked it quickly to a nice medium rare. It was perfect! Again, I'm glad we were manning the grill. These could have easily been over cooked and ruined. We actually got another order of the filet mignon. The server finally brings in the prime kalbi. He says that this is their signature dish. It was very tender and sweet, but it didn't leave an everlasting impression with my palate. Would I still pho'ks with it?  Sure. The first four orders is a definate though. So in the end, the crack that will have me on the come back is the carpaccio and the filet mignon. WINNER!\\n\\nYay!, I'm a fan!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df7cd0-23cd-458f-b2b5-f025c3b9fe62",
   "metadata": {},
   "source": [
    "## 预处理数据\n",
    "\n",
    "### Tokenizing(填充/截断)\n",
    "\n",
    "下载数据集到本地后，使用 Tokenizer 来处理文本，对于长度不等的输入数据，可以使用填充（padding）和截断（truncation）策略来处理。\n",
    "\n",
    "Datasets 的 `map` 方法，支持一次性在整个数据集上应用预处理函数。\n",
    "\n",
    "下面使用填充到最大长度的策略，处理整个数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bf2b342-e1dd-4ab6-ad57-28eb2513ae38",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize_function\u001b[39m(examples):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer(examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m], padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 10\u001b[0m tokenized_datasets \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241m.\u001b[39mmap(tokenize_function, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)  # default batch size is 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47a415a8-cd15-4a8c-851b-9b4740ef8271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 star</td>\n",
       "      <td>I ate. I payed good tip. And I throwed up in the evening and ruined my whole vegas plan.</td>\n",
       "      <td>[101, 146, 8756, 119, 146, 2653, 1174, 1363, 5580, 119, 1262, 146, 4932, 1174, 1146, 1107, 1103, 3440, 1105, 9832, 1139, 2006, 1396, 11305, 2197, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5 stars</td>\n",
       "      <td>All I know is. The Hubs and I were hungry so I yelped a burger joint in PHX. I was all Bae this place has 254 reviews .. Let's go there ! We were in PHX from Prescott for the day. Got the Teriyaki Burger Rocket size and fries ! delishioursh ! Hit The Spot ! The owner even chased us to the parking lot to make sure we enjoyed our Food  Yay!!!!!</td>\n",
       "      <td>[101, 1398, 146, 1221, 1110, 119, 1109, 20164, 4832, 1105, 146, 1127, 7555, 1177, 146, 6798, 1233, 3537, 170, 171, 23872, 4091, 1107, 153, 3048, 3190, 119, 146, 1108, 1155, 18757, 1162, 1142, 1282, 1144, 24613, 3761, 119, 119, 2421, 112, 188, 1301, 1175, 106, 1284, 1127, 1107, 153, 3048, 3190, 1121, 22721, 1111, 1103, 1285, 119, 7348, 1103, 12008, 16383, 2293, 24435, 17100, 2060, 1105, 175, 3377, 106, 3687, 20800, 24453, 1324, 106, 15375, 1109, 28091, 106, 1109, 3172, 1256, 13781, 1366, 1106, 1103, 5030, 1974, 1106, 1294, 1612, 1195, 4927, 1412, 6702, 14680, 1183, 106, 106, 106, 106, ...]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5 stars</td>\n",
       "      <td>This place is delicious! We dined here with a party of six so we were able to sample a lot of of different dishes. The favorites were the bacon wrapped dates with blue cheese (need I say more?), the tuna tartare, and flash fried peppers. We also had the filet mignon sliders, the stuffed mushrooms, and grilled shrimp. It was all very good. We also shared a carafe of sangria, although some in our group did not like the sangria, so we also ordered a bottle of wine. We did not have room for dessert, so I will have to go back for that. And the price was right, I think our bill was $200 for 6 of us!</td>\n",
       "      <td>[101, 1188, 1282, 1110, 13108, 106, 1284, 28028, 1174, 1303, 1114, 170, 1710, 1104, 1565, 1177, 1195, 1127, 1682, 1106, 6876, 170, 1974, 1104, 1104, 1472, 10514, 119, 1109, 25735, 1127, 1103, 20503, 4293, 4595, 1114, 2221, 9553, 113, 1444, 146, 1474, 1167, 136, 114, 117, 1103, 189, 9291, 27629, 16242, 1874, 117, 1105, 6746, 15688, 18700, 1116, 119, 1284, 1145, 1125, 1103, 4956, 1204, 1940, 25566, 1179, 7253, 1733, 117, 1103, 12084, 25590, 1116, 117, 1105, 176, 26327, 1181, 23982, 119, 1135, 1108, 1155, 1304, 1363, 119, 1284, 1145, 3416, 170, 1610, 9823, 1162, 1104, 6407, 3464, 117, 1780, ...]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(tokenized_datasets[\"train\"], num_examples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c33d153-f729-4f04-972c-a764c1cbbb8b",
   "metadata": {},
   "source": [
    "### 数据抽样\n",
    "\n",
    "使用 1000 个数据样本，在 BERT 上演示小规模训练（基于 Pytorch Trainer）\n",
    "\n",
    "`shuffle()`函数会随机重新排列列的值。如果您希望对用于洗牌数据集的算法有更多控制，可以在此函数中指定generator参数来使用不同的numpy.random.Generator。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a17317d8-3c6a-467f-843d-87491f600db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 star</td>\n",
       "      <td>2 stars is being generous. 1 star is for a great location in Old Montreal and the other star is because my wife likes their salt and pepper chicken wings.\\nIt fails at being a sports bar. Sure they show a few games but they simultaneously pipe in Whitney Houston and Celine Dion greatest hits over the sound system.\\nFood has no imagination, variety or taste.\\nService and management are very weak.\\nHave had several issues over the 5 times that I have been there with no satisfactory resolutions.\\nWaste of a great location in Le Vieux Port!</td>\n",
       "      <td>[101, 123, 2940, 1110, 1217, 12839, 119, 122, 2851, 1110, 1111, 170, 1632, 2450, 1107, 2476, 5206, 1105, 1103, 1168, 2851, 1110, 1272, 1139, 1676, 7407, 1147, 6870, 1105, 18700, 9323, 4743, 119, 165, 183, 2240, 1204, 12169, 1120, 1217, 170, 2865, 2927, 119, 6542, 1152, 1437, 170, 1374, 1638, 1133, 1152, 7344, 9415, 1107, 9567, 4666, 1105, 24664, 2568, 21322, 4459, 4919, 1166, 1103, 1839, 1449, 119, 165, 183, 2271, 13465, 1144, 1185, 10405, 117, 2783, 1137, 5080, 119, 165, 183, 1708, 1200, 14301, 1105, 2635, 1132, 1304, 4780, 119, 165, 183, 3048, 8308, 1125, 1317, 2492, 1166, 1103, ...]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n",
    "\n",
    "show_random_elements(small_train_dataset, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b65d63-2d3a-4a56-bc31-6e88a29e9dec",
   "metadata": {},
   "source": [
    "## 微调训练配置\n",
    "\n",
    "### 加载 BERT 模型\n",
    "\n",
    "警告通知我们正在丢弃一些权重（`vocab_transform` 和 `vocab_layer_norm` 层），并随机初始化其他一些权重（`pre_classifier` 和 `classifier` 层）。在微调模型情况下是绝对正常的，因为我们正在删除用于预训练模型的掩码语言建模任务的头部，并用一个新的头部替换它，对于这个新头部，我们没有预训练的权重，所以库会警告我们在用它进行推理之前应该对这个模型进行微调，而这正是我们要做的事情。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d2af4df-abd4-4a4b-94b6-b0e7375304ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /root/autodl-tmp/hf/hub/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44014df-b52c-4c72-9e9f-54424725a473",
   "metadata": {},
   "source": [
    "### 了解训练超参数（TrainingArguments）\n",
    "\n",
    "完整配置参数与默认值：https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/trainer#transformers.TrainingArguments\n",
    "\n",
    "源代码定义：https://github.com/huggingface/transformers/blob/v4.36.1/src/transformers/training_args.py#L161\n",
    "\n",
    "**最重要配置：模型权重保存路径(output_dir)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98c01d5c-de72-4ff0-b11d-e07ac5346888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "# logging_steps 默认值为500，根据我们的训练数据和步长，将其设置为100\n",
    "training_args = TrainingArguments(output_dir=model_output_dir,\n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  num_train_epochs=5,\n",
    "                                  logging_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ce03480-3aaa-48ea-a0c6-a177b8d8e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=models/bert-base-cased-finetune-yelp/runs/May12_15-53-19_autodl-container-bde111aa08-e28e8944,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=100,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=5,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "output_dir=models/bert-base-cased-finetune-yelp,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=models/bert-base-cased-finetune-yelp,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 完整的超参数配置\n",
    "print(training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebd3365-d359-4ab4-a300-4717590cc240",
   "metadata": {},
   "source": [
    "### 训练过程中的指标评估（Evaluate)\n",
    "\n",
    "**[Hugging Face Evaluate 库](https://huggingface.co/docs/evaluate/index)** 支持使用一行代码，获得数十种不同领域（自然语言处理、计算机视觉、强化学习等）的评估方法。 当前支持 **完整评估指标：https://huggingface.co/evaluate-metric**\n",
    "\n",
    "训练器（Trainer）在训练过程中不会自动评估模型性能。因此，我们需要向训练器传递一个函数来计算和报告指标。 \n",
    "\n",
    "Evaluate库提供了一个简单的准确率函数，您可以使用`evaluate.load`函数加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a8ef138-5bf2-41e5-8c68-df8e11f4e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(metric_name_or_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d406c0-56d0-4a54-9c6c-e126ab7f5254",
   "metadata": {},
   "source": [
    "\n",
    "接着，调用 `compute` 函数来计算预测的准确率。\n",
    "\n",
    "在将预测传递给 compute 函数之前，我们需要将 logits 转换为预测值（**所有Transformers 模型都返回 logits**）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f46d2e59-1ebf-43d2-bc86-6b57a4d24d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2feba67-9ca9-4793-9a15-3eaa426df2a1",
   "metadata": {},
   "source": [
    "#### 实例化训练超参数（含训练过程指标监控）\n",
    "\n",
    "通常，为了监控训练过程中的评估指标变化，我们可以在`TrainingArguments`指定`evaluation_strategy`参数，以便在 epoch 结束时报告评估指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afaaee18-4986-4e39-8ad9-b8d413ab4cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=model_output_dir,\n",
    "                                  evaluation_strategy=\"epoch\", \n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  num_train_epochs=3,\n",
    "                                  logging_steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47d6981-e444-4c0f-a7cb-dd7f2ba8df12",
   "metadata": {},
   "source": [
    "## 训练\n",
    "\n",
    "### 实例化训练器（Trainer）\n",
    "\n",
    "`kernel version` 版本问题：暂不影响本示例代码运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca1d12ac-89dc-4c30-8282-f859724c0062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a833e0db-1168-4a3c-8b75-bfdcef8c5157",
   "metadata": {},
   "source": [
    "### 使用 nvidia-smi 查看 GPU 使用\n",
    "\n",
    "为了实时查看GPU使用情况，可以使用 `watch` 指令实现轮询：`watch -n 1 nvidia-smi`:\n",
    "\n",
    "```shell\n",
    "Every 1.0s: nvidia-smi                                                   Wed Dec 20 14:37:41 2023\n",
    "\n",
    "Wed Dec 20 14:37:41 2023\n",
    "+---------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
    "|-----------------------------------------+----------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                      |               MIG M. |\n",
    "|=========================================+======================+======================|\n",
    "|   0  Tesla T4                       Off | 00000000:00:0D.0 Off |                    0 |\n",
    "| N/A   64C    P0              69W /  70W |   6665MiB / 15360MiB |     98%      Default |\n",
    "|                                         |                      |                  N/A |\n",
    "+-----------------------------------------+----------------------+----------------------+\n",
    "\n",
    "+---------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                            |\n",
    "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
    "|        ID   ID                                                             Usage      |\n",
    "|=======================================================================================|\n",
    "|    0   N/A  N/A     18395      C   /root/miniconda3/bin/python                6660MiB |\n",
    "+---------------------------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18112981-1d0e-4934-a0cf-a00783bd6f18",
   "metadata": {},
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "accfe921-471d-481a-96da-c491cdebad0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [189/189 01:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.516700</td>\n",
       "      <td>1.131185</td>\n",
       "      <td>0.611000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.275600</td>\n",
       "      <td>1.201985</td>\n",
       "      <td>0.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.082400</td>\n",
       "      <td>1.332099</td>\n",
       "      <td>0.633000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=189, training_loss=0.29609230397239567, metrics={'train_runtime': 92.1772, 'train_samples_per_second': 32.546, 'train_steps_per_second': 2.05, 'total_flos': 789354427392000.0, 'train_loss': 0.29609230397239567, 'epoch': 3.0})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8c5c50-04e0-4a42-b729-5a5fb09a28d8",
   "metadata": {},
   "source": [
    "## 评估\n",
    "### 选取评估数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d581099-37a4-4470-b051-1ada38554089",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=64).select(range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a41507-eb43-4d46-a3ab-7115a93dc830",
   "metadata": {},
   "source": [
    "### 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ffb47eab-1370-491e-8a84-6d5347a350b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.6001545190811157,\n",
       " 'eval_accuracy': 0.57,\n",
       " 'eval_runtime': 0.8718,\n",
       " 'eval_samples_per_second': 114.705,\n",
       " 'eval_steps_per_second': 14.912,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(small_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a55686-7c43-4ab8-a5cd-0e77f14c7c52",
   "metadata": {},
   "source": [
    "### 保存模型和训练状态\n",
    "\n",
    "- 使用 `trainer.save_model` 方法保存模型，后续可以通过 from_pretrained() 方法重新加载\n",
    "- 使用 `trainer.save_state` 方法保存训练状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ad0cbc14-9ef7-450f-a1a3-4f92b6486f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(model_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "badf5868-2847-439d-a73e-42d1cca67b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd92e35d-fed7-4ff2-aa84-27b5e29b917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.model.save_pretrained(\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61828934-01da-4fc3-9e75-8d754c25dfbc",
   "metadata": {},
   "source": [
    "## Homework: 使用完整的 YelpReviewFull 数据集训练，看 Acc 最高能到多少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ee2580a-7a5a-46ae-a28b-b41e9e838eb1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6631635692804705b99510106a0aded3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/320000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 准备数据集\n",
    "dataset = load_dataset(dataset_name_or_path)\n",
    "\n",
    "# preprocess\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "medium_train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(320000)).map(tokenize_function, batched=True)\n",
    "medium_eval_dataset = dataset[\"test\"].shuffle(seed=42).select(range(50000)).map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44348f80-25b5-4563-9755-a4029c37508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(metric_name_or_path)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33217817-241f-4801-a607-41743261359b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /root/autodl-tmp/hf/hub/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='410' max='60939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  410/60939 04:39 < 11:30:14, 1.46 it/s, Epoch 0.02/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, num_labels=5)\n",
    "# 训练参数\n",
    "\n",
    "training_args = TrainingArguments(output_dir=model_output_dir,\n",
    "                                  per_device_train_batch_size=32,\n",
    "                                  num_train_epochs=3)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=medium_train_dataset,\n",
    "    eval_dataset=medium_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23959b86-ba8b-4d95-8717-5a153ac8025c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m medium_test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshuffle(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50000\u001b[39m))\u001b[38;5;241m.\u001b[39mmap(tokenize_function, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m trainer\u001b[38;5;241m.\u001b[39mevaluate(medium_test_dataset)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "medium_test_dataset = dataset[\"test\"].shuffle(seed=64).select(range(50000)).map(tokenize_function, batched=True)\n",
    "trainer.evaluate(medium_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dcf159-e0b1-4f27-b4ad-fc5fdb259998",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
